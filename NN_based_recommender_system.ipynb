{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samarkouki65/Recommendation_Systeme_Movies/blob/main/NN_based_recommender_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT8AyHRMNh41"
      },
      "source": [
        "# Basic recommender\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-reQ11gbLB"
      },
      "source": [
        "In this tutorial, we build a simple matrix factorization model using the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/) with TFRS. We can use this model to recommend movies for a given user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA00wBE2Ntdm"
      },
      "source": [
        "### Import TFRS\n",
        "\n",
        "First, install and import TFRS:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yzAaM85Z12D"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q jinja2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3oYt3R6Nr9l"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Text\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n"
      ],
      "metadata": {
        "id": "VUFt2lYJm2JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxQ1CZcO2wh"
      },
      "source": [
        "### Read the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_full = tfds.load('movielens/100k-ratings', split=\"train\")\n",
        "\n",
        "user_ids = ratings_full.map(lambda x: x[\"user_id\"])\n",
        "unique_user_ids = np.unique(list(tfds.as_numpy(user_ids)))\n",
        "\n",
        "movie_titles = ratings_full.map(lambda x: x[\"movie_title\"])\n",
        "unique_movie_titles = np.unique(list(tfds.as_numpy(movie_titles)))"
      ],
      "metadata": {
        "id": "DvC9VVXOHlXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### TODO\n",
        ">\n",
        "> Display the ten first examples to explore the list of available informations\n",
        ">\n",
        "> Usefull: `Dataset.take(count)`, `tfds.as_numpy()`, `tfds.as_dataframe()`\n"
      ],
      "metadata": {
        "id": "PgKXUeSO868N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_user_ids.size)"
      ],
      "metadata": {
        "id": "ZgB-Pp4peRrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_movie_titles.size)"
      ],
      "metadata": {
        "id": "JKbh2HtlecFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " La proportion des Ã©valuations existantes par rapport au nombre total de combinaisons utilisateur-film possibles."
      ],
      "metadata": {
        "id": "dM6XcRkPfxY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ratings_full.cardinality().numpy()/(unique_user_ids.size*unique_movie_titles.size))"
      ],
      "metadata": {
        "id": "MSKnbUVhefB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# here is the new code I added\n",
        "#list(ratings_full.as_numpy_iterator())[0:10]\n",
        "list(ratings_full.take(1).as_numpy_iterator())"
      ],
      "metadata": {
        "id": "DWXpgQVzHpwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restrict the dataset to used features."
      ],
      "metadata": {
        "id": "dm-Ummuy93Tb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-mxBYjdO5m7"
      },
      "outputs": [],
      "source": [
        "# Ratings data.\n",
        "ratings = ratings_full.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"user_rating\": x[\"user_rating\"],\n",
        "    \"timestamp\": x[\"timestamp\"],\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(ratings.take(5).as_numpy_iterator())"
      ],
      "metadata": {
        "id": "JBAuM1sTgHuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into a training set and a testing set."
      ],
      "metadata": {
        "id": "dXCQpH2LMSf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)\n",
        "\n",
        "cached_train = train.shuffle(100_000).batch(2048)\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "Oj5OYXLjMSqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lrch6rVBOB9Q"
      },
      "source": [
        "### Define a model\n",
        "\n",
        "We can define a prediction model by inheriting from `tf.keras.Model` and implementing the `call` method.\n",
        "\n",
        "> ### TODO\n",
        ">\n",
        "> Draw the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DotRankingModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # Compute embeddings for users.\n",
        "    self.user_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute embeddings for movies.\n",
        "    self.movie_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute predictions.\n",
        "    self.ratings = tf.keras.layers.Dot(axes=(1))\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    user_embedding = self.user_embeddings(features[\"user_id\"])\n",
        "    movie_embedding = self.movie_embeddings(features[\"movie_title\"])\n",
        "\n",
        "    return self.ratings((user_embedding, movie_embedding))"
      ],
      "metadata": {
        "id": "XFalJDcOU4_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model instance\n",
        "model = DotRankingModel()\n",
        "\n",
        "# Define input layers to wrap the model for visualization\n",
        "user_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name=\"user_id\")\n",
        "movie_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name=\"movie_title\")\n",
        "\n",
        "# Call the model on dummy inputs to create a Keras Model for visualization\n",
        "output = model({\"user_id\": user_input, \"movie_title\": movie_input})\n",
        "visual_model = tf.keras.Model(inputs=[user_input, movie_input], outputs=output)\n",
        "\n",
        "# Generate and save model visualization\n",
        "plot_model(visual_model, to_file=\"dot_ranking_model.png\", show_shapes=True, show_layer_names=True, dpi=100)\n",
        "\n",
        "# Display image in Colab\n",
        "plt.figure(figsize=(10, 6))\n",
        "img = plt.imread(\"dot_ranking_model.png\")\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")  # Hide axes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zFASoH6MmqGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display model summary\n",
        "visual_model.summary()"
      ],
      "metadata": {
        "id": "Dj93XHCFnfUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"user_id\": tf.constant([\"42\", \"42\"]),\n",
        "    \"movie_title\": tf.constant([\"One Flew Over the Cuckoo's Nest (1975)\", \"Strictly Ballroom (1992)\"])\n",
        "}\n",
        "DotRankingModel()(inputs)"
      ],
      "metadata": {
        "id": "9Y6hsvwWc7ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define a TFRS model by inheriting from `tfrs.Model` and implementing the `compute_loss` method.\n",
        "\n",
        "> ### TODO\n",
        ">\n",
        "> Explain the role played by this model"
      ],
      "metadata": {
        "id": "hnm3Monk-HbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MovieLensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, rating_model: tf.keras.Model):\n",
        "    super().__init__()\n",
        "    self.ranking_model = rating_model\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
        "      loss = tf.keras.losses.MeanSquaredError(),\n",
        "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    return self.ranking_model(features)\n",
        "\n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    labels = features.pop(\"user_rating\")\n",
        "\n",
        "    rating_predictions = self(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(labels=labels, predictions=rating_predictions)"
      ],
      "metadata": {
        "id": "NXOntFjKdjaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit and test the model"
      ],
      "metadata": {
        "id": "6Zca6clv-dWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retrieval model.\n",
        "model = MovieLensModel(DotRankingModel())\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "\n",
        "# Train and test\n",
        "dot_model_history = model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=1,\n",
        "    epochs=10,\n",
        "    verbose=1)\n",
        "\n",
        "test_accuracy = dot_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
        "print(f\"RMSE: {test_accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "Y4jBtrYAU8LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"RMSE\");\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "caiEkjUGfGVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ### TODO\n",
        ">\n",
        "> Comment the curve"
      ],
      "metadata": {
        "id": "Y8_8re05-taq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More complex link between user's and item's representations\n",
        "\n",
        "Let replace the dot product between user's and item's representations by a fully connected layer of size 64, followed by a fully connected layer with a unique output.\n",
        "\n",
        "> ### TODO\n",
        ">\n",
        "> - Define the layer and adapt the `call` method\n",
        "> - Choose carefully the activation functions of the layers\n",
        ">\n",
        "> USefull: `tf.keras.Sequential`, `tf.keras.Dense`, `tf.concat`"
      ],
      "metadata": {
        "id": "GFyPZmqQl4Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneLayerRankingModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # Compute embeddings for users.\n",
        "    self.user_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute embeddings for movies.\n",
        "    self.movie_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    # Compute predictions.\n",
        "    self.ratings = # TODO here\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    user_embedding = self.user_embeddings(features[\"user_id\"])\n",
        "    movie_embedding = self.movie_embeddings(features[\"movie_title\"])\n",
        "\n",
        "    return self.ratings(# TODO here)"
      ],
      "metadata": {
        "id": "65LzTZe8mYbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DotRankingModel()({\"user_id\": [\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\"]})"
      ],
      "metadata": {
        "id": "nAx8po39mYj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retrieval model.\n",
        "model = MovieLensModel(OneLayerRankingModel())\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "\n",
        "# Train and test\n",
        "one_layer_model_history = model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=1,\n",
        "    epochs=10,\n",
        "    verbose=1)\n",
        "\n",
        "test_accuracy = one_layer_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
        "print(f\"RMSE: {test_accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "MomtyxVvmY0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
        "plt.plot(one_layer_model_history.history[\"val_root_mean_squared_error\"], label=\"one layer\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"RMSE\");\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "KCLZjF9Nok4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Taking advantage of context features\n",
        "\n",
        "Let use timestamps of the ratings and movie titles to enrich the input of the model.\n",
        "\n",
        "Some preliminary:"
      ],
      "metadata": {
        "id": "ooZ4g25P0YSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timestamps = np.concatenate(list(ratings_full.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
        "\n",
        "max_timestamp = timestamps.max()\n",
        "min_timestamp = timestamps.min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")"
      ],
      "metadata": {
        "id": "lSeZJBJI4rUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New user model.\n",
        "\n",
        "> ### TODO\n",
        ">\n",
        "> Draw and explain the role played by the components of the model"
      ],
      "metadata": {
        "id": "1Xe9ghj84-ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnrichedRankingModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    embedding_dimension = 32\n",
        "\n",
        "    # Building blocks to compute embeddings for users.\n",
        "    self.user_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_user_ids, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    self.timestamp_embeddings = tf.keras.Sequential([\n",
        "        tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "        tf.keras.layers.Embedding(len(timestamp_buckets) + 1, embedding_dimension),\n",
        "    ])\n",
        "\n",
        "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "        axis=None\n",
        "    )\n",
        "    self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "    # Building blocks to compute embeddings for movies.\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.movie_embeddings = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "        vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
        "      max_tokens=max_tokens)\n",
        "\n",
        "    self.title_text_embeddings = tf.keras.Sequential([\n",
        "      self.title_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, embedding_dimension, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer.adapt(unique_movie_titles)\n",
        "\n",
        "\n",
        "\n",
        "    # Compute predictions.\n",
        "    self.ratings = tf.keras.Sequential([\n",
        "      # Learn multiple dense layers.\n",
        "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "      # Make rating predictions in the final layer.\n",
        "      tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
        "    user_embedding = tf.concat([\n",
        "        self.user_embeddings(features[\"user_id\"]),\n",
        "        self.timestamp_embeddings(features[\"timestamp\"]),\n",
        "        tf.reshape(self.normalized_timestamp(features[\"timestamp\"]), (-1, 1)),\n",
        "    ], axis=1)\n",
        "\n",
        "    movie_embedding = tf.concat([\n",
        "        self.movie_embeddings(features[\"movie_title\"]),\n",
        "        self.title_text_embeddings(features[\"movie_title\"]),\n",
        "    ], axis=1)\n",
        "\n",
        "    return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
      ],
      "metadata": {
        "id": "PLcCzx-SzSBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EnrichedRankingModel()({\"user_id\": [\"42\"], \"movie_title\":[\"One Flew Over the Cuckoo's Nest (1975)\"], \"timestamp\":[879024327]})"
      ],
      "metadata": {
        "id": "4L9AP2s-1GCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a retrieval model.\n",
        "model = MovieLensModel(EnrichedRankingModel())\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
        "\n",
        "# Train and test\n",
        "enriched_model_history = model.fit(\n",
        "    cached_train,\n",
        "    validation_data=cached_test,\n",
        "    validation_freq=1,\n",
        "    epochs=10,\n",
        "    verbose=1)\n",
        "\n",
        "test_accuracy = enriched_model_history.history[\"val_root_mean_squared_error\"][-1]\n",
        "print(f\"RMSE: {test_accuracy:.2f}.\")"
      ],
      "metadata": {
        "id": "NPrbGZZ22bzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(dot_model_history.history[\"val_root_mean_squared_error\"], label=\"basic\")\n",
        "plt.plot(one_layer_model_history.history[\"val_root_mean_squared_error\"], label=\"one layer\")\n",
        "plt.plot(enriched_model_history.history[\"val_root_mean_squared_error\"], label=\"enriched\")\n",
        "plt.title(\"Accuracy vs epoch\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"RMSE\");\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "KqpESO5v2bzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# More comple models\n",
        "\n",
        "\n",
        "\n",
        "> ### TODO\n",
        ">\n",
        "> Build and test more complex models:\n",
        "> - with more layers to link user's and item's representation\n",
        "> - integrating more contextual information: user's age, movie's genre, ...\n",
        "\n"
      ],
      "metadata": {
        "id": "9mdYyJSs7QPY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyVMhMsnRcN0"
      },
      "source": [
        "# Copyright\n",
        "\n",
        "Several section of this notebook originate from notebooks under the following copyright:\n",
        "\n",
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfR1i3oKRcOD"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}